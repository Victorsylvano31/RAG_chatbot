import os
import re
import shutil
import logging
from pathlib import Path
from typing import List, Optional, Any

# Imports LangChain avec loaders PDF sp√©cialis√©s
from langchain_community.document_loaders import PyPDFLoader, PyMuPDFLoader, UnstructuredPDFLoader
from langchain_text_splitters import RecursiveCharacterTextSplitter
from langchain_community.embeddings import HuggingFaceEmbeddings
from langchain_community.vectorstores import Chroma

# ==========================
# CONFIGURATION
# ==========================
class Config:
    CHUNK_SIZE = 512  # Taille r√©duite pour les livres techniques
    CHUNK_OVERLAP = 50
    MIN_DOC_LENGTH = 10
    EMBEDDING_MODEL = "sentence-transformers/all-MiniLM-L6-v2"

# ==========================
# SETUP LOGGING
# ==========================
def setup_logging():
    logging.basicConfig(
        level=logging.INFO,
        format="%(asctime)s | %(levelname)-8s | %(message)s",
        datefmt="%Y-%m-%d %H:%M:%S"
    )
    return logging.getLogger(__name__)

# ==========================
# PDF TEXT CLEANER
# ==========================
class PDFTextCleaner:
    """Nettoyeur sp√©cialis√© pour le texte extrait de PDF"""
    
    @staticmethod
    def clean_pdf_text(text: str) -> str:
        """Nettoie le texte des PDF selon les bonnes pratiques LangChain"""
        if not text or not isinstance(text, str):
            return ""
        
        # 1. Suppression des caract√®res de contr√¥le et Unicode probl√©matiques
        text = re.sub(r'[\x00-\x08\x0B\x0C\x0E-\x1F\x7F]', '', text)
        
        # 2. Nettoyage des caract√®res Unicode sp√©ciaux fr√©quents dans les PDF
        text = re.sub(r'[\u200b-\u200f\u2028-\u202e\ufeff]', '', text)
        
        # 3. Gestion des c√©sures de mots en fin de ligne
        text = re.sub(r'(\w+)-\s*\n\s*(\w+)', r'\1\2', text)
        
        # 4. Normalisation des espaces et retours √† la ligne
        text = re.sub(r'\s+', ' ', text)
        text = re.sub(r'\n+', '\n', text)
        
        # 5. Suppression des en-t√™tes/pieds de page typiques des livres
        lines = text.split('\n')
        cleaned_lines = []
        for line in lines:
            line = line.strip()
            # Ignorer les lignes trop courtes ou num√©ros de page
            if (len(line) > 3 and 
                not line.isdigit() and 
                not re.match(r'^[ivxlc]+$', line.lower())):
                cleaned_lines.append(line)
        
        text = ' '.join(cleaned_lines)
        
        return text.strip()

# ==========================
# PDF LOADER STRATEGY
# ==========================
class PDFLoaderStrategy:
    """Strat√©gie de chargement PDF avec fallbacks"""
    
    def __init__(self, logger: logging.Logger):
        self.logger = logger
        self.cleaner = PDFTextCleaner()
    
    def load_pdf(self, file_path: Path) -> Optional[List[Any]]:
        """Charge un PDF avec diff√©rentes strat√©gies"""
        strategies = [
            self._try_pymupdf,  # Meilleur pour l'extraction texte
            self._try_pypdf,     # Fallback standard
        ]
        
        for strategy in strategies:
            try:
                documents = strategy(file_path)
                if documents and len(documents) > 0:
                    return documents
            except Exception as e:
                self.logger.warning(f"‚ùå {strategy.__name__} √©chou√©: {e}")
                continue
        
        return None
    
    def _try_pymupdf(self, file_path: Path) -> Optional[List[Any]]:
        """Essaie PyMuPDF (meilleur pour la pr√©cision)"""
        try:
            # PyMuPDF est g√©n√©ralement meilleur pour l'extraction texte
            loader = PyMuPDFLoader(str(file_path))
            docs = loader.load()
            
            # Nettoyage approfondi
            for doc in docs:
                doc.page_content = self.cleaner.clean_pdf_text(doc.page_content)
            
            self.logger.info(f"‚úÖ PyMuPDF: {len(docs)} pages")
            return docs
        except ImportError:
            self.logger.warning("üìö PyMuPDF non install√©, utilisation de PyPDF")
            return None
    
    def _try_pypdf(self, file_path: Path) -> Optional[List[Any]]:
        """Essaie PyPDF (fallback)"""
        loader = PyPDFLoader(str(file_path))
        docs = loader.load()
        
        # Nettoyage approfondi
        for doc in docs:
            doc.page_content = self.cleaner.clean_pdf_text(doc.page_content)
        
        self.logger.info(f"‚úÖ PyPDF: {len(docs)} pages")
        return docs

# ==========================
# DOCUMENT PROCESSOR
# ==========================
class DocumentProcessor:
    def __init__(self, logger: logging.Logger):
        self.logger = logger
    
    def create_chunks(self, documents: List[Any]) -> List[Any]:
        """Cr√©e des chunks valid√©s"""
        if not documents:
            return []
        
        # Validation des documents
        valid_docs = []
        for doc in documents:
            if (hasattr(doc, 'page_content') and 
                doc.page_content and 
                isinstance(doc.page_content, str)):
                
                # Validation de longueur
                if len(doc.page_content.strip()) >= Config.MIN_DOC_LENGTH:
                    valid_docs.append(doc)
        
        self.logger.info(f"üìÑ Documents valides: {len(valid_docs)}")
        
        if not valid_docs:
            return []
        
        # Cr√©ation des chunks
        splitter = RecursiveCharacterTextSplitter(
            chunk_size=Config.CHUNK_SIZE,
            chunk_overlap=Config.CHUNK_OVERLAP,
            length_function=len,
            separators=["\n\n", "\n", ". ", "! ", "? ", " ", ""]
        )
        
        chunks = splitter.split_documents(valid_docs)
        
        # Validation finale
        valid_chunks = []
        for chunk in chunks:
            if (hasattr(chunk, 'page_content') and 
                chunk.page_content and 
                isinstance(chunk.page_content, str) and
                len(chunk.page_content.strip()) >= 10):
                
                valid_chunks.append(chunk)
        
        self.logger.info(f"‚úÇÔ∏è  Chunks valides: {len(valid_chunks)}")
        return valid_chunks

# ==========================
# VECTOR STORE BUILDER - VERSION SIMPLIFI√âE
# ==========================
class VectorStoreBuilder:
    def __init__(self, chroma_path: str, logger: logging.Logger):
        self.chroma_path = Path(chroma_path)
        self.logger = logger
        
        # Embedding model simple et stable
        self.embeddings = HuggingFaceEmbeddings(
            model_name=Config.EMBEDDING_MODEL
        )
    
    def safe_build_vector_store(self, chunks: List[Any]) -> Optional[Chroma]:
        """Construction s√©curis√©e de la base vectorielle"""
        if not chunks:
            self.logger.error("‚ùå Aucun chunk √† vectoriser")
            return None
        
        # Nettoyage
        if self.chroma_path.exists():
            shutil.rmtree(self.chroma_path)
        
        try:
            self.logger.info("üî® Construction base vectorielle...")
            
            # M√©thode DIRECTE de LangChain (la plus stable)
            vector_store = Chroma.from_documents(
                documents=chunks,
                embedding=self.embeddings,
                persist_directory=str(self.chroma_path)
            )
            
            self.logger.info(f"‚úÖ Base sauvegard√©e: {self.chroma_path}")
            return vector_store
            
        except Exception as e:
            self.logger.error(f"‚ùå Erreur construction: {e}")
            return None

# ==========================
# PIPELINE PRINCIPAL
# ==========================
class PDFIngestionPipeline:
    """Pipeline sp√©cialis√© pour l'ingestion de livres PDF"""
    
    def __init__(self, data_path: str = "../data", chroma_path: str = "../chroma_db"):
        self.data_path = Path(data_path)
        self.chroma_path = Path(chroma_path)
        self.logger = setup_logging()
        
        self.pdf_loader = PDFLoaderStrategy(self.logger)
        self.processor = DocumentProcessor(self.logger)
        self.vector_builder = VectorStoreBuilder(chroma_path, self.logger)
    
    def run_ingestion(self) -> bool:
        """Ex√©cute le pipeline complet"""
        self.logger.info("üöÄ D√âMARRAGE INGESTION PDF")
        
        # 1. Trouver le PDF
        pdf_files = list(self.data_path.glob("*.pdf"))
        if not pdf_files:
            self.logger.error("‚ùå Aucun PDF trouv√©")
            return False
        
        pdf_file = pdf_files[0]  # Prendre le premier PDF
        self.logger.info(f"üìñ Traitement: {pdf_file.name}")
        
        # 2. Chargement du PDF
        documents = self.pdf_loader.load_pdf(pdf_file)
        if not documents:
            self.logger.error("‚ùå √âchec chargement PDF")
            return False
        
        # 3. D√©coupage en chunks
        chunks = self.processor.create_chunks(documents)
        if not chunks:
            self.logger.error("‚ùå √âchec cr√©ation chunks")
            return False
        
        # 4. Construction base vectorielle
        vector_store = self.vector_builder.safe_build_vector_store(chunks)
        
        if vector_store:
            self.logger.info("üéâ INGESTION R√âUSSIE!")
            return True
        else:
            self.logger.error("üí• √âCHEC CONSTRUCTION BASE")
            return False

# ==========================
# EX√âCUTION
# ==========================
if __name__ == "__main__":
    # Installation de PyMuPDF si n√©cessaire
    try:
        import fitz  # PyMuPDF
    except ImportError:
        print("üì¶ Installation de PyMuPDF...")
        os.system("pip install pymupdf")
    
    pipeline = PDFIngestionPipeline("../data", "../chroma_db")
    success = pipeline.run_ingestion()
    
    if success:
        pipeline.logger.info("‚ú® PR√äT POUR LA SUITE DU PROJET!")
    else:
        pipeline.logger.error("üí• V√âRIFIEZ LE FICHIER PDF")
        exit(1)